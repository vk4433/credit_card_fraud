{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score,recall_score,f1_score\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned_credit.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 30)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data[\"Class\"]\n",
    "data.drop(\"Class\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.05)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    max_features=1.0,\n",
    "    contamination=0.05\n",
    ")\n",
    "iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"anomaly_scor\"] = iso.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>anomaly_scor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  anomaly_scor  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964             1  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475             1  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686             1  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534             1  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403             1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anomaly_scor\n",
       " 1    269539\n",
       "-1     14187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.anomaly_scor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pred\"] = data[\"anomaly_scor\"].apply(lambda x:1 if x ==-1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = data[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[269461,  13792],\n",
       "       [    78,    395]], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_true,y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.9511148079485137\n",
      "\n",
      " Precision: 0.027842390921265947\n",
      "\n",
      " Recall: 0.8350951374207188\n",
      "\n",
      " F1 Score: 0.0538881309686221\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"\\n Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"\\n Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"\\n F1 Score: {f1_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df[\"Class\"]==1]\n",
    "n_fraud = df[df[\"Class\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_n_fraud =n_fraud.sample(len(fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_data = pd.concat([fraud,re_n_fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "1 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "2 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "3 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "4  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276 -0.353229      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  1.761758      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  0.606031      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573 -0.117342      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793 -0.349231      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "oy_true = un_data[\"Class\"]\n",
    "x = un_data.drop(\"Class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.05)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    max_features=1.0,\n",
    "    contamination=0.05\n",
    ")\n",
    "iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"anomaly_scor\"] = iso.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"pred\"] = x[\"anomaly_scor\"].apply(lambda x:1 if x ==-1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.5422832980972516\n",
      "\n",
      " Precision: 0.9166666666666666\n",
      "\n",
      " Recall: 0.09302325581395349\n",
      "\n",
      " F1 Score: 0.1689059500959693\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Accuracy: {accuracy_score(oy_true, y_pred)}\")\n",
    "print(f\"\\n Precision: {precision_score(oy_true, y_pred)}\")\n",
    "print(f\"\\n Recall: {recall_score(oy_true, y_pred)}\")\n",
    "print(f\"\\n F1 Score: {f1_score(oy_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis = 1) \n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshape,y_reshape = SMOTE().fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17561686, 566506)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape.size,y_reshape.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.05)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    max_features=1.0,\n",
    "    contamination=0.05\n",
    ")\n",
    "iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"anomaly_scor\"] = iso.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred\"] = df[\"anomaly_scor\"].apply(lambda x:1 if x ==-1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred = df[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [566506, 283726]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_reshape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_score(y_reshape,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall_score(y_reshape,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\polam\\OneDrive\\Desktop\\assignment\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\polam\\OneDrive\\Desktop\\assignment\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\polam\\OneDrive\\Desktop\\assignment\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\polam\\OneDrive\\Desktop\\assignment\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [566506, 283726]"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Accuracy: {accuracy_score(y_reshape, y_pred)}\")\n",
    "print(f\"\\n Precision: {precision_score(y_reshape, y_pred)}\")\n",
    "print(f\"\\n Recall: {recall_score(y_reshape, y_pred)}\")\n",
    "print(f\"\\n F1 Score: {f1_score(y_reshape, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
